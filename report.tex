\documentclass[a4paper,11pt]{article}

\usepackage{cite}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{fancyheadings}
\usepackage{geometry}
\usepackage{multicol}
\usepackage{amsmath}
\usepackage[]{mcode}
\usepackage{pdfpages}

 \newcommand{\ba}[1]{\begin{align*}    #1    \end{align*}}
 \newcommand{\ban}[1]{\begin{align}    #1    \end{align}}
 \renewcommand{\vec}[1]{\mathbf{#1}}

 \definecolor{light-gray}{gray}{0.95}

\setlength{\headsep}{1in}

\pagestyle{fancy}

\lhead{ridenour@kth.se \\ herczka@kth.se}
\rhead{Parallel Programming for Large-Scale Problems SF2568}
\title{Parallel Programming for Large-Scale Problems SF2568 \\
Teacher: Michael Hanke \\
Homework 2: The Jacobi Iteration}
\author{Jonathan Ridenour, 780514-7779\\
Mateusz Herczka, 700624-9234}

\begin{document}
\lstdefinestyle{customc}{
 backgroundcolor=\color{light-gray},
  belowcaptionskip=1\baselineskip,
  breaklines=true,
  frame=L,
  xleftmargin=\parindent,
  language=C,
  showstringspaces=false,
  basicstyle=\footnotesize\ttfamily,
  keywordstyle=\bfseries\color{green!40!black},
  commentstyle=\itshape\color{purple!40!black},
  identifierstyle=\color{blue},
  stringstyle=\color{orange},
}

\lstdefinestyle{output}{
 backgroundcolor=\color{light-gray},
 language=bash,
 xleftmargin=\parindent,
 keywordstyle=\color{blue},
 basicstyle=\ttfamily,
 morekeywords={peter@kbpet},
 %alsoletter={:~$},
 morekeywords=[2]{peter@kbpet:},
}
\maketitle
\pagebreak
\section*{Task 1}
\subsection*{a)}
An algorithm for the broadcast operation requiring $\mathcal{O}(\text{log}_2(P))$ communication steps (where $P$ is the number of processes which must receive the information) is as follows.    In each of $n$ steps, let each process $P_i$ ($i$ = 0, 2, . . . , $P-1$) which has the information, send the information to a process $P_{i+P/2^n}$ which needs it.  Each process communicates with that process which is halfway between itself and either the next process which is already informed or the end of the process array.  For example, if $P$ = 8, we get
%\begin{table}[h]
\begin{center}
\begin{tabular}{l r}
 $n=1$: & $P_0 \rightarrow P_4$ \\\\
 $n=2$: & $P_0 \rightarrow P_2$ \\
	 & $P_4 \rightarrow P_6$\\\\
 $n=3$: & $P_0 \rightarrow P_1$ \\
	 & $P_2 \rightarrow P_3$\\
	 & $P_4 \rightarrow P_5$\\
	 & $P_6 \rightarrow P_7$
\end{tabular}
\end{center}
%\end{table}
In this way, the number of active processes doubles with each new step.  Note that if $P = 2^d$ for some integer $d$, then the number of communication steps is exactly $\text{log}_2(P)$, otherwise there will be a number of extra communications which must be carried out.  The number of these "extra" communications will be less than than of another full step however, and thus the dominating term will generally be $\mathcal{O}(\text{log}_2(P))$.

\subsection*{b)}
Assume that $P = 2^n$.  Let $t_s$, $t_d$, and $w$ be the startup time for each processor, the data transfer time, and the size of the information to be transfered, respectively.  Then we can write the time per step as 
\ba{
\text{time per step } = t_s + t_dw.}  
As mentioned above, the number of steps is $n$.  This gives that the total time can be written 
\ba{
\text{total time }=(t_s + t_dw) n = (t_s + t_dw) \cdot \text{log}_2{P}.
}

\subsection*{c)}
The scatter operation can be implemented in a similar fashion as the one-to-all broadcast operation described above.  The root process, which contains all the messages intended for the other processes, sends out half the messages in the first step, one fourth of the messages in the second step, and so on.  Say that we have $P-1$ messages, with $M_i$ intended for process $i$, $i$ = 0, 1, . . . , $P-1$.  Then again, as an example with $P$ = 8, we get the following message schedule.  Note that those messages enclosed in parenthesis to the left of the process indicate those messages which are withheld; while those messages which appear above the right arrow indicate those which are sent to the corresponding process.
\begin{center}
\begin{tabular}{l r}
$n=0$:  & $(M_0,M_1,M_2,M_3,M_4,M_5,M_6,M_7) P_0$ \\\\
 $n=1$: & $(M_0,M_1,M_2,M_3) P_0 \overset{(M_4,M_5,M_6,M_7)}{\longrightarrow} P_4$ \\\\
 $n=2$: & $(M_0,M_1) P_0 \overset{(M_2,M_3)}{ \longrightarrow} P_2$ \\
	 & $(M_4,M_5) P_4 \overset{(M_6,M_7) }{\longrightarrow} P_6$\\\\
 $n=3$: & $(M_0) P_0 \overset{(M_1)}{ \longrightarrow}  P_1$ \\
	 & $(M_2)P_2 \overset{(M_3)}{ \longrightarrow}  P_3$\\
	 & $(M_4)P_4 \overset{(M_5)}{ \longrightarrow}  P_5$\\
	 & $(M_6)P_6 \overset{(M_7)}{ \longrightarrow}    P_7$\\\\
$n=4$: & $(M_0)P_0$\\
& $(M_1)P_1$ \\
& $(M_2)P_2$ \\
& $(M_3)P_3 $\\
& $(M_4)P_4 $\\
& $(M_5)P_5$ \\
& $(M_6)P_6$ \\
& $(M_7)P_7$	 
\end{tabular}
\end{center}  
Note that step $n=0$ indicates the initial state, with all messages assembled at the root process (no communication takes place); whereas step $n=4$ represents the final state, with all messages distributed to the proper process (again, no communication takes place).  Thus the task is carried out with the same number of communication steps as the broadcast algorithm, $\mathcal{O}(\text{log}_2(P))$.
 
\section*{Task 2}
\subsection*{a)}
\subsection*{b)}

\section*{Task 3}

We now consider the 1-dimensional differential equation
\ba{
u'' + r(x)u = & \ f(x), \ \ \ \ \ 0<x<1,\\
u(0) = & \  u(1) = 0,
}
where
\ba{
r(x) = & \ x^3,\\
f(x) = & \ \frac{-1}{x^{1.5}}.
}

%\begin{figure}
%\makebox[\textwidth][c]{\includegraphics[width=1.2\textwidth]{brot3}}
%  \caption{Zoom 2.}
%  \label{fig:brot3}
%\end{figure}

\section*{Appendix}
\begin{lstlisting}[style=customc]
\end{lstlisting}
%\begin{thebibliography}{}
%\bibitem{Wilkinson} Barry Wilkinson, Michael Allen {\it Parallel Programming, Techniques and Applications Using Networked Workstations and Parallel Computers}, 2005, Pearson Prentice Hall, pp 9.
%\end{thebibliography}
\end{document}